{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad0ede4-2046-4a2c-b8ee-010a136088cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:51:34.543460Z",
     "iopub.status.busy": "2023-04-30T18:51:34.542457Z",
     "iopub.status.idle": "2023-04-30T18:51:34.559264Z",
     "shell.execute_reply": "2023-04-30T18:51:34.559264Z",
     "shell.execute_reply.started": "2023-04-30T18:51:34.543460Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f92570-b0e0-416a-88d1-89630368fee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:51:29.211045Z",
     "iopub.status.busy": "2023-04-30T18:51:29.210042Z",
     "iopub.status.idle": "2023-04-30T18:51:29.227906Z",
     "shell.execute_reply": "2023-04-30T18:51:29.227906Z",
     "shell.execute_reply.started": "2023-04-30T18:51:29.211045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add Yolo v7 Repository to Python path\n",
    "\n",
    "pth_yolov7 = pathlib.Path(r'C:\\Users\\edpar\\OneDrive\\Documents\\git\\github\\yolov7')\n",
    "\n",
    "if not str(pth_yolov7) in sys.path:\n",
    "    sys.path.append(str(pth_yolov7))\n",
    "\n",
    "from utils.general import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eef7ae-f836-4319-bb2b-bafd66f900b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:50:49.273948Z",
     "iopub.status.busy": "2023-04-30T18:50:49.273948Z",
     "iopub.status.idle": "2023-04-30T18:50:51.838853Z",
     "shell.execute_reply": "2023-04-30T18:50:51.838853Z",
     "shell.execute_reply.started": "2023-04-30T18:50:49.273948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edpar\\miniconda3\\envs\\ed-pytorch\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "# Initialize Torch device, model and get stride\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model_path = str(pth_yolov7 / 'yolov7.pt')\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "model = ckpt['model'].float().fuse().eval()\n",
    "for m in model.modules():\n",
    "    if type(m) in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU]:\n",
    "        m.inplace = True  # pytorch 1.7.0 compatibility\n",
    "    elif type(m) is nn.Upsample:\n",
    "        m.recompute_scale_factor = None  # torch 1.11.0 compatibility\n",
    "model.half();\n",
    "\n",
    "stride = int(model.stride.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d25e69dd-3da1-417b-8395-48e17ef5eeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:50:52.677952Z",
     "iopub.status.busy": "2023-04-30T18:50:52.677447Z",
     "iopub.status.idle": "2023-04-30T18:50:52.684710Z",
     "shell.execute_reply": "2023-04-30T18:50:52.684710Z",
     "shell.execute_reply.started": "2023-04-30T18:50:52.677952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def letterbox(im, new_width, stride):\n",
    "    \"\"\"Resizes image to new width while maintaining aspect ratio, and trims to ensure height is a multiple of stride.\"\"\"\n",
    "    new_width = int(new_width)\n",
    "    h, w = im.shape[:2]\n",
    "    r = new_width / w\n",
    "    scaled_height = int(r * h)\n",
    "    im = cv2.resize(im, (new_width, scaled_height), interpolation=cv2.INTER_LINEAR)\n",
    "    trim_rows = scaled_height % stride\n",
    "    if trim_rows != 0:\n",
    "        final_height = scaled_height - trim_rows\n",
    "        offset = trim_rows // 2\n",
    "        im = im[offset:(offset + final_height)]\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3724a889-ab51-43c0-966e-e78798fe79bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:50:55.310376Z",
     "iopub.status.busy": "2023-04-30T18:50:55.310376Z",
     "iopub.status.idle": "2023-04-30T18:50:55.324471Z",
     "shell.execute_reply": "2023-04-30T18:50:55.324471Z",
     "shell.execute_reply.started": "2023-04-30T18:50:55.310376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(model, img, device):\n",
    "    \"\"\"Runs a PyTorch model on the input image tensor after preprocessing it.\"\"\"\n",
    "    img = np.expand_dims(img, 0)\n",
    "    img = img[:, :, :, ::-1].transpose(0, 3, 1, 2)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device).half()\n",
    "    img /= 255.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        return model(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cdf66f1-67d6-4621-af2e-4d968132e747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:58:26.380388Z",
     "iopub.status.busy": "2023-04-30T18:58:26.380388Z",
     "iopub.status.idle": "2023-04-30T18:58:26.386401Z",
     "shell.execute_reply": "2023-04-30T18:58:26.386401Z",
     "shell.execute_reply.started": "2023-04-30T18:58:26.380388Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_one_box(x, img, label, color):\n",
    "    \"\"\"Draws a rectangle on the input image, adds a label with the given color, and writes it on the image.\"\"\"\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=1, lineType=cv2.LINE_AA)\n",
    "    t_size = cv2.getTextSize(label, 0, fontScale=1/3, thickness=1)[0]\n",
    "    c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "    cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)\n",
    "    cv2.putText(img, label, (c1[0], c1[1] - 2), 0, 1/3, [225, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "def plot_boxes(img, pred, names, colors):\n",
    "    \"\"\"Draws rectangles and writes labels on an input image for each detection prediction from a list.\"\"\"\n",
    "    for det in pred:\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            label = f'{names[int(cls)]} {conf:.2f}'\n",
    "            plot_one_box(xyxy, img, label, colors[int(cls)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f553d43-76da-45ab-a56e-5d900668e91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T18:58:33.212797Z",
     "iopub.status.busy": "2023-04-30T18:58:33.211794Z",
     "iopub.status.idle": "2023-04-30T18:59:05.437861Z",
     "shell.execute_reply": "2023-04-30T18:59:05.437861Z",
     "shell.execute_reply.started": "2023-04-30T18:58:33.212797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the input image size and enable benchmark mode for CuDNN to speed up inference.\n",
    "imgsz = 640\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Get the class names for the model and generate random colors for drawing boxes on the image.\n",
    "names = model.names\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "# Open the default camera for capturing video.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop until the camera is closed.\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the camera and ensure successfully read\n",
    "        ret, im0 = cap.read()\n",
    "        assert ret, \"Failed to read\"\n",
    "\n",
    "        # Resize and pad the image to the specified size while maintaining the aspect ratio.\n",
    "        img = letterbox(im0, imgsz, stride)\n",
    "        \n",
    "        # Run the model on the preprocessed image.\n",
    "        pred = run_model(model, img, device)\n",
    "        \n",
    "        # Perform non-maximum suppression to remove overlapping boxes.\n",
    "        pred = non_max_suppression(pred)\n",
    "        \n",
    "        # Draw the boxes on the image and display it.\n",
    "        plot_boxes(img, pred, names, colors)\n",
    "        cv2.imshow(\"YOLO v7 Demo\", img)\n",
    "        \n",
    "        # Exit the loop if the user presses the 'q' key.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    # Release the camera and close all windows.\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
